{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cabb11f5",
   "metadata": {},
   "source": [
    "This is the minimal implementation of this solution of Petfinder Pawpularity, The number of folds, epochs and other models selection are reduced due to longer time training, but the overall strategy is demonstrated.\n",
    "### Overview\n",
    "The 2nd-place Pawpularity solution used a two-stage hybrid ensemble. In the first stage, they trained many different image models such as Swin, ViT, ConvNeXt, and CaiT using various image sizes and loss functions (BCE, MSE, Poisson, CE) to maximize diversity. In the second stage, they combined the out-of-fold predictions from those models with metadata features (including information merged from the older PetFinder competition using image hashing) and trained a LightGBM regressor . The final weights for combining models were refined with a least-squares regression, minimizing RMSE on validation data. \n",
    "### Strength\n",
    "This approach worked well because of its model variety and feature engineering of new inputs from the previous competition as well as image aspect. \n",
    "### Differences to our model\n",
    "The authors used a broader range of architectures and metadata integration techniques compared to our approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "496c0c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting image shapes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ab29c826494478987a4bcd3e6f1fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated height mean=904.28, std=156.91\n",
      "Calculated width mean=804.43, std=270.21\n",
      "Sturges' rule: n=9912, bins=14\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import timm\n",
    "import albumentations as A\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "import imagehash\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "BASE_PATH = \"inputs/\"\n",
    "# --- Metadata Column Names ---\n",
    "METADATA_COLS = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', \n",
    "                 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n",
    "\n",
    "\n",
    "# --- 1. Data Loading, Metadata Processing, and Stratified Folds ---\n",
    "train = pd.read_csv(BASE_PATH + 'train.csv') \n",
    "train['file'] = train['Id'].apply(lambda x: f'{BASE_PATH}train/{x}.jpg')\n",
    "\n",
    "# Standardize the Pawpularity target (0-1) and extract metadata features\n",
    "train['target_normalized'] = train['Pawpularity'] / 100.0\n",
    "\n",
    "IMAGE_COLS = [\"width\",\"height\",\"aspect\"]\n",
    "\n",
    "METADATA_DIM = len(METADATA_COLS+IMAGE_COLS) # Should be 15\n",
    "train['file'] = train['Id'].apply(lambda x: f'{BASE_PATH}train/{x}.jpg')\n",
    "\n",
    "\n",
    "# --- Add width, height, aspect columns ---\n",
    "def add_image_shape_features(df):\n",
    "    heights, widths = [], []\n",
    "\n",
    "    print(\"Extracting image shapes...\")\n",
    "    for path in tqdm(df['file'].values):\n",
    "        try:\n",
    "            with Image.open(path) as img:\n",
    "                heights.append(img.height)\n",
    "                widths.append(img.width)\n",
    "        except:\n",
    "            heights.append(np.nan)\n",
    "            widths.append(np.nan)\n",
    "\n",
    "    df['height'] = heights\n",
    "    df['width'] = widths\n",
    "    df['aspect'] = df['height'] / df['width']\n",
    "\n",
    "    \n",
    "\n",
    "    # --- Compute mean/std  ---\n",
    "    h_mean, h_std = df['height'].mean(), df['height'].std()\n",
    "    w_mean, w_std = df['width'].mean(), df['width'].std()\n",
    "\n",
    "    print(f'Calculated height mean={h_mean:.2f}, std={h_std:.2f}')\n",
    "    print(f'Calculated width mean={w_mean:.2f}, std={w_std:.2f}')\n",
    "\n",
    "    # --- Standardize height and width ---\n",
    "    df['height'] = (df['height'] - h_mean) / h_std\n",
    "    df['width'] = (df['width'] - w_mean) / w_std\n",
    "\n",
    "    return df\n",
    "\n",
    "train = add_image_shape_features(train)\n",
    "train['metadata'] = train[METADATA_COLS+IMAGE_COLS].values.tolist() # Store metadata as a list/array per row\n",
    "# --- Create bins using Sturges' rule ---\n",
    "# k = 1 + 3.322 * log10(n)\n",
    "n = len(train)\n",
    "k = int(1 + 3.322 * math.log10(n))\n",
    "train['bin'] = pd.cut(train['Pawpularity'], bins=k, labels=False)\n",
    "\n",
    "print(f\"Sturges' rule: n={n}, bins={k}\")\n",
    "\n",
    "# --- 5-Fold Stratified Split ---\n",
    "train['fold'] = -1\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "for i, (_, val_idx) in enumerate(skf.split(train, train['bin'])):\n",
    "    train.loc[val_idx, 'fold'] = i\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "\n",
    "OOF_SAVE_DIR = \"top2Hash\"\n",
    "os.makedirs(OOF_SAVE_DIR, exist_ok=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8874c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>...</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "      <th>file</th>\n",
       "      <th>target_normalized</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>aspect</th>\n",
       "      <th>metadata</th>\n",
       "      <th>bin</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>inputs/train/0007de18844b0dbbb5e1f607da0606e0.jpg</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-1.174489</td>\n",
       "      <td>-1.478196</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>inputs/train/0009c66b9439883ba2750fb825e1d7db.jpg</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.830334</td>\n",
       "      <td>0.842205</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>inputs/train/0013fd999caf9a3efe1352ca1b0d937e.jpg</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.355090</td>\n",
       "      <td>-0.312445</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>inputs/train/0018df346ac9c1d8413cfcc888ca8246.jpg</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-1.174489</td>\n",
       "      <td>-1.478196</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>inputs/train/001dc955e10590d3ca4673f034feeef2.jpg</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.355090</td>\n",
       "      <td>-0.978588</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "2  0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
       "3  0018df346ac9c1d8413cfcc888ca8246              0     1     1     1       0   \n",
       "4  001dc955e10590d3ca4673f034feeef2              0     0     0     1       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  ...  Blur  Pawpularity  \\\n",
       "0          0      1        0      0  ...     0           63   \n",
       "1          0      0        0      0  ...     0           42   \n",
       "2          0      0        0      1  ...     0           28   \n",
       "3          0      0        0      0  ...     0           15   \n",
       "4          0      1        0      0  ...     0           72   \n",
       "\n",
       "                                                file  target_normalized  \\\n",
       "0  inputs/train/0007de18844b0dbbb5e1f607da0606e0.jpg               0.63   \n",
       "1  inputs/train/0009c66b9439883ba2750fb825e1d7db.jpg               0.42   \n",
       "2  inputs/train/0013fd999caf9a3efe1352ca1b0d937e.jpg               0.28   \n",
       "3  inputs/train/0018df346ac9c1d8413cfcc888ca8246.jpg               0.15   \n",
       "4  inputs/train/001dc955e10590d3ca4673f034feeef2.jpg               0.72   \n",
       "\n",
       "     height     width    aspect  \\\n",
       "0 -1.174489 -1.478196  1.777778   \n",
       "1 -0.830334  0.842205  0.750000   \n",
       "2  0.355090 -0.312445  1.333333   \n",
       "3 -1.174489 -1.478196  1.777778   \n",
       "4  0.355090 -0.978588  1.777778   \n",
       "\n",
       "                                            metadata  bin fold  \n",
       "0  [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...    8    4  \n",
       "1  [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    5    3  \n",
       "2  [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...    3    4  \n",
       "3  [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    1    0  \n",
       "4  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   10    0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fcc0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PART 1: DEFINING DATASET AND MODELS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PART 1: DATASET AND MODEL DEFINITIONS\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PART 1: DEFINING DATASET AND MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "class PetDataset(Dataset):\n",
    "    def __init__(self, image_paths, targets, metadata, transform=None, target_dtype=torch.float):\n",
    "        self.image_paths = image_paths\n",
    "        self.targets = targets \n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "        self.target_dtype = target_dtype\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        \n",
    "        image = image / 255.0\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        \n",
    "        return {\n",
    "            'image': torch.tensor(image, dtype=torch.float),\n",
    "            'metadata': torch.tensor(self.metadata[idx], dtype=torch.float),\n",
    "            'target': torch.tensor(self.targets[idx], dtype=self.target_dtype)\n",
    "        }\n",
    "\n",
    "\n",
    "def get_transforms(img_size=224, is_train=True):\n",
    "    if is_train:\n",
    "        return A.Compose([\n",
    "            A.Resize(img_size, img_size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Rotate(limit=15, p=0.5),\n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([A.Resize(img_size, img_size)])\n",
    "\n",
    "\n",
    "class PetModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes, metadata_dim, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Image backbone\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=0) \n",
    "        self.feature_dim = self.model.num_features\n",
    "        \n",
    "        # Final head with metadata\n",
    "        total_input_dim = self.feature_dim + metadata_dim\n",
    "        \n",
    "        self.final_head = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(total_input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_img, x_meta):\n",
    "        img_features = self.model(x_img)\n",
    "        combined_features = torch.cat([img_features, x_meta], dim=1)\n",
    "        out = self.final_head(combined_features)\n",
    "        \n",
    "        if self.num_classes == 1:\n",
    "            return out.squeeze(-1)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0a23d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# PART 2: TRAINING FUNCTION\n",
    "\n",
    "\n",
    "def train_dl_model(model_name, train_df, loss_type, n_epochs, batch_size, \n",
    "                   img_size, lr, save_dir):\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    n_folds = 5\n",
    "    oof_preds = np.zeros(len(train_df), dtype=float)\n",
    "    max_patience = 3\n",
    "\n",
    "    if loss_type == 'BCE':\n",
    "        num_classes = 1\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        target_dtype = torch.float\n",
    "    else:\n",
    "        raise ValueError(\"Only BCE supported in this simplified version\")\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Model: {model_name} | Fold {fold+1}/{n_folds}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        tr_ind = train_df['fold'] != fold\n",
    "        val_ind = train_df['fold'] == fold\n",
    "        \n",
    "        tr_paths = train_df.loc[tr_ind, 'file'].values\n",
    "        val_paths = train_df.loc[val_ind, 'file'].values\n",
    "        val_targets_original = train_df.loc[val_ind, 'Pawpularity'].values \n",
    "        \n",
    "        tr_metadata = np.stack(train_df.loc[tr_ind, 'metadata'].values)\n",
    "        val_metadata = np.stack(train_df.loc[val_ind, 'metadata'].values)\n",
    "        \n",
    "        # Normalize to [0, 1] for BCE\n",
    "        tr_targets = train_df.loc[tr_ind, 'Pawpularity'].values / 100.0\n",
    "        val_targets_normalized = train_df.loc[val_ind, 'Pawpularity'].values / 100.0\n",
    "        \n",
    "        train_dataset = PetDataset(\n",
    "            tr_paths, tr_targets, tr_metadata,\n",
    "            transform=get_transforms(img_size, is_train=True),\n",
    "            target_dtype=target_dtype\n",
    "        )\n",
    "        val_dataset = PetDataset(\n",
    "            val_paths, val_targets_normalized, val_metadata,\n",
    "            transform=get_transforms(img_size, is_train=False),\n",
    "            target_dtype=target_dtype\n",
    "        )\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                                  num_workers=0, pin_memory=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size*2, shuffle=False, \n",
    "                               num_workers=0, pin_memory=True)\n",
    "\n",
    "        model = PetModel(model_name, num_classes=num_classes, \n",
    "                        metadata_dim=METADATA_DIM, pretrained=True).to(device)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=3, T_mult=1)\n",
    "\n",
    "        best_val_rmse = float('inf')\n",
    "        best_val_preds = None\n",
    "        patience = 0\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            train_count = 0\n",
    "            \n",
    "            for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs} [Train]\"):\n",
    "                imgs = batch['image'].to(device)\n",
    "                metas = batch['metadata'].to(device) \n",
    "                tgts = batch['target'].to(device) \n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                logits = model(imgs, metas)\n",
    "                loss = criterion(logits, tgts)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item() * len(imgs)\n",
    "                train_count += len(imgs)\n",
    "            \n",
    "            avg_train_loss = train_loss / train_count\n",
    "            scheduler.step()\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_preds = []\n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{n_epochs} [Valid]\"):\n",
    "                    imgs = batch['image'].to(device)\n",
    "                    metas = batch['metadata'].to(device) \n",
    "                    logits = model(imgs, metas)\n",
    "                    scaled = torch.sigmoid(logits) * 100.0\n",
    "                    val_preds.extend(scaled.cpu().numpy())\n",
    "\n",
    "            val_preds = np.clip(np.array(val_preds), 1, 100)\n",
    "            val_rmse = np.sqrt(np.mean((val_targets_original - val_preds) ** 2))\n",
    "            \n",
    "            print(f\"   Epoch {epoch+1}/{n_epochs} | Train Loss: {avg_train_loss:.4f} | Val RMSE: {val_rmse:.4f}\", end='')\n",
    "\n",
    "            if val_rmse < best_val_rmse:\n",
    "                best_val_rmse = val_rmse\n",
    "                best_val_preds = val_preds.copy()\n",
    "                torch.save(model.state_dict(), \n",
    "                          os.path.join(save_dir, f\"{model_name}_fold{fold}.pth\"))\n",
    "                patience = 0\n",
    "                print(\" -> **BEST**\")\n",
    "            else:\n",
    "                patience += 1\n",
    "                print(f\" | Patience: {patience}/{max_patience}\")\n",
    "                \n",
    "                if patience >= max_patience:\n",
    "                    print(f\"   Early stopping triggered\")\n",
    "                    break\n",
    "\n",
    "        oof_preds[val_ind.values] = best_val_preds\n",
    "        print(f\"Fold {fold+1} Complete | Best RMSE: {best_val_rmse:.4f}\")\n",
    "        \n",
    "        del model, optimizer, scheduler, train_dataset, val_dataset, train_loader, val_loader\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    overall_rmse = np.sqrt(np.mean((train_df['Pawpularity'].values - oof_preds) ** 2))\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{model_name} - Overall OOF RMSE: {overall_rmse:.4f}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    np.save(os.path.join(save_dir, f\"oof_{model_name}.npy\"), oof_preds)\n",
    "    return oof_preds, overall_rmse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fed70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PART 3: TRAINING STAGE 1 DL MODELS\n",
      "================================================================================\n",
      "\n",
      "################################################################################\n",
      "Training: efficientnet_b0\n",
      "################################################################################\n",
      "\n",
      "======================================================================\n",
      "Model: efficientnet_b0 | Fold 1/5\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766a548ca1954d97ba8bd8881688cffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d98b1bffc645da96cc53ccb94d8f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 0.6559 | Val RMSE: 18.7465 -> **BEST**\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517fdd64e0994a17a0e77c0d28fb6e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df65a3ccbcb34cad8c19c3311c2befad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 0.6380 | Val RMSE: 19.3189 | Patience: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7925c9eb7b742d8a7497e401fdb2b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d732ee7ebcea4099bd21d7e56f5f941f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 0.6227 | Val RMSE: 19.5310 | Patience: 2/3\n",
      "Fold 1 Complete | Best RMSE: 18.7465\n",
      "\n",
      "======================================================================\n",
      "Model: efficientnet_b0 | Fold 2/5\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9496dbade47b45c59b7b7f8dfc975f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f347ed5f1244f08f9702e3ab6f723e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 0.6553 | Val RMSE: 18.7774 -> **BEST**\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ef0302e4314161b2442a3ac4ccebfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068a20f0fdee4df789c4d53e420d04bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 0.6367 | Val RMSE: 19.0271 | Patience: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae02fda5c80949f181851f2e0960329e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3857941a3ec41239a4f82275f6fbce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 0.6208 | Val RMSE: 19.4870 | Patience: 2/3\n",
      "Fold 2 Complete | Best RMSE: 18.7774\n",
      "\n",
      "======================================================================\n",
      "Model: efficientnet_b0 | Fold 3/5\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6fbd3919f14f92b6aef20aa1e0497a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e64c26c690d4d3f9b1f2bacd50bde72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 0.6552 | Val RMSE: 18.5248 -> **BEST**\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccd773ab33847a3a5a18c1efb3ac175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6ebb975eba4cf593d62e292389a42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 0.6377 | Val RMSE: 18.9750 | Patience: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2234c47023d40d581ed391e2fe0286c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d5c4e825404d64b02bca99af406dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 0.6218 | Val RMSE: 18.9532 | Patience: 2/3\n",
      "Fold 3 Complete | Best RMSE: 18.5248\n",
      "\n",
      "======================================================================\n",
      "Model: efficientnet_b0 | Fold 4/5\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54fa314eae0742018cd7f8c82f4e3cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d9f76f17594199ad9b7a3960355393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 0.6552 | Val RMSE: 18.8393 -> **BEST**\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbebf082c2fb4121bbc8672e56517e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6982ef8aa544a89cfa36dc408500c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 0.6385 | Val RMSE: 18.7096 -> **BEST**\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c36188544354b4faf08d8c37c2aec39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab395cb2fbd24db8baab68a23a6b4858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 0.6226 | Val RMSE: 18.9618 | Patience: 1/3\n",
      "Fold 4 Complete | Best RMSE: 18.7096\n",
      "\n",
      "======================================================================\n",
      "Model: efficientnet_b0 | Fold 5/5\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d914d80293438192fd7b9d2cb5f7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc7e42e5d1946e88edb80bd3555ad93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 0.6539 | Val RMSE: 19.0245 -> **BEST**\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e033f80576d44c23bab315ddfd546d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1331cae37fe94310b8b122c9fe12dfc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 0.6365 | Val RMSE: 19.3644 | Patience: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae335037a3504d52ac1914abf13ec3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c71d69c5314bd39398f87bdecc48f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 0.6209 | Val RMSE: 19.8411 | Patience: 2/3\n",
      "Fold 5 Complete | Best RMSE: 19.0245\n",
      "\n",
      "======================================================================\n",
      "efficientnet_b0 - Overall OOF RMSE: 18.7573\n",
      "======================================================================\n",
      "\n",
      "################################################################################\n",
      "Training: convnext_tiny\n",
      "################################################################################\n",
      "\n",
      "======================================================================\n",
      "Model: convnext_tiny | Fold 1/5\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43072c956514d93803a9b9cf4d6f9a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005791d02f86455a9f29872b5a354839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 0.6676 | Val RMSE: 20.7367 -> **BEST**\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2beba84cf441868c0d578bef4ab369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfdfe6fc71e4fa0bc0e8a6b94493703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 0.6655 | Val RMSE: 20.7544 | Patience: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a361e3cc75c4476a9edc0c4efec801b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0efc1349f8fc4003bcd501f9a012ea25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 0.6651 | Val RMSE: 20.6994 -> **BEST**\n",
      "Fold 1 Complete | Best RMSE: 20.6994\n",
      "\n",
      "======================================================================\n",
      "Model: convnext_tiny | Fold 2/5\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339503a7031c4d289d22a8308cf2d86d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be0ff6b87c442949482497d14e2dbd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 0.6683 | Val RMSE: 20.6018 -> **BEST**\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e069baf8b9ee41febca80f2e77fc7fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8271667dc18540bd9d941faed1dec163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 0.6653 | Val RMSE: 20.6424 | Patience: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520e7b4824594e2e8f4f2af31e00a936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba588a20a00843b2ab1b65a9d2902213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 0.6650 | Val RMSE: 20.5642 -> **BEST**\n",
      "Fold 2 Complete | Best RMSE: 20.5642\n",
      "\n",
      "======================================================================\n",
      "Model: convnext_tiny | Fold 3/5\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bf7cebe88c41cb80d380b6014080fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081b10f5dd6c43aa8677d55766a7044b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 0.6624 | Val RMSE: 20.5298 -> **BEST**\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8ecf1fdf084417ad8e88bef2b72467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fca6dc5e6044645a626e8aa7376c0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 0.6490 | Val RMSE: 18.4238 -> **BEST**\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d56ead0daa44ed49878e42d4964b157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2f252197504008a48f16734e44c399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 0.6341 | Val RMSE: 18.3637 -> **BEST**\n",
      "Fold 3 Complete | Best RMSE: 18.3637\n",
      "\n",
      "======================================================================\n",
      "Model: convnext_tiny | Fold 4/5\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef91648d78b6434faffe90355e28cba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694a53c303d142bf82840c97709c587c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 0.6672 | Val RMSE: 20.6014 -> **BEST**\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505cd26d27c3474dba499ff2ea747498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f14333943914fa389bb771feffca804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 0.6655 | Val RMSE: 20.7611 | Patience: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5c8a45336b415d8f6be55919d9755b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e3da187e644732af817f8bae9efc0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 0.6591 | Val RMSE: 19.0296 -> **BEST**\n",
      "Fold 4 Complete | Best RMSE: 19.0296\n",
      "\n",
      "======================================================================\n",
      "Model: convnext_tiny | Fold 5/5\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c89154401a4da8bfc168d2686a8145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ca333ce0984fbda18d563dc9926530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 0.6682 | Val RMSE: 20.5827 -> **BEST**\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3e38172e1d46b18d7b4d7f27bbad03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d151bf2954a94382abf54e9559f9680d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 0.6652 | Val RMSE: 20.6130 | Patience: 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0c640488884c1cb52b318c5dde8d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Train]:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a8fc20631a44f38ced4988895906e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Valid]:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 0.6650 | Val RMSE: 20.5637 -> **BEST**\n",
      "Fold 5 Complete | Best RMSE: 20.5637\n",
      "\n",
      "======================================================================\n",
      "convnext_tiny - Overall OOF RMSE: 19.8676\n",
      "======================================================================\n",
      "\n",
      "================================================================================\n",
      "STAGE 1 COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PART 3: TRAIN STAGE 1 MODELS (2 MODELS)\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PART 3: TRAINING STAGE 1 DL MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "stage1_models_config = [\n",
    "   # Model 1: Simple Regression (BCE  Loss)\n",
    "    {\"name\": \"efficientnet_b0\", \"size\": 224, \"loss_type\": \"BCE\", \"lr\": 1e-4, \"epochs\": 3, \"batch_size\": 26},\n",
    "    {\"name\": \"convnext_tiny\", \"size\": 224, \"loss_type\": \"BCE\", \"lr\": 5e-5, \"epochs\": 3, \"batch_size\": 26},\n",
    "]\n",
    "\n",
    "stage1_oofs = {}\n",
    "\n",
    "for cfg in stage1_models_config:\n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(f\"Training: {cfg['name']}\")\n",
    "    print(f\"{'#'*80}\")\n",
    "    \n",
    "    oof, rmse = train_dl_model(\n",
    "        model_name=cfg[\"name\"],\n",
    "        train_df=train,\n",
    "        loss_type=\"BCE\",\n",
    "        n_epochs=cfg[\"epochs\"],\n",
    "        batch_size=cfg[\"batch_size\"],\n",
    "        img_size=cfg[\"size\"],\n",
    "        lr=cfg[\"lr\"],\n",
    "        save_dir=OOF_SAVE_DIR\n",
    "    )\n",
    "    \n",
    "    stage1_oofs[cfg['name']] = oof\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAGE 1 COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741e55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PART 4: HASHING AND MERGING WITH PREVIOUS COMPETITION\n",
      "================================================================================\n",
      "Hashing current competition images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182882dc17c64de7871dac9a91d0152c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading previous competition data...\n",
      "Hashing previous competition images ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a97ec661014499bf5d198bf41f3816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14993 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous competition: 2020 images hashed\n",
      "\n",
      "Merging competitions by image hash...\n",
      "Matched images: 218 (2.2%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# PART 4: HASH AND MERGE WITH PREVIOUS COMPETITION\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PART 4: HASHING AND MERGING WITH PREVIOUS COMPETITION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Hash current competition images\n",
    "print(\"Hashing current competition images...\")\n",
    "train['hash'] = None\n",
    "for idx, row in tqdm(train.iterrows(), total=len(train)):\n",
    "    try:\n",
    "        img = Image.open(row['file']).convert('RGB')\n",
    "        train.at[idx, 'hash'] = str(imagehash.average_hash(img))\n",
    "    except Exception as e:\n",
    "        print(f\"Error hashing {row['file']}: {e}\")\n",
    "\n",
    "# Load and hash previous competition\n",
    "print(\"\\nLoading previous competition data...\")\n",
    "prev_train = pd.read_csv(f'{BASE_PATH}pet_adopt/train/train.csv')\n",
    "prev_image_dir = f'{BASE_PATH}pet_adopt/train_images/'\n",
    "\n",
    "print(\"Hashing previous competition images ...\")\n",
    "prev_hashes = []\n",
    "for idx, row in tqdm(prev_train.iterrows(), total=len(prev_train)):\n",
    "    pet_id = row['PetID']\n",
    "    img_path = f\"{prev_image_dir}/{pet_id}-1.jpg\"\n",
    "    \n",
    "    if os.path.exists(img_path):\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_hash = str(imagehash.average_hash(img))\n",
    "            prev_hashes.append({\n",
    "                'PetID': pet_id,\n",
    "                'hash': img_hash,\n",
    "                'path': img_path\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error hashing {img_path}: {e}\")\n",
    "\n",
    "prev_hashes_df = pd.DataFrame(prev_hashes)\n",
    "\n",
    "# Merge previous metadata\n",
    "prev_hashes_df = prev_hashes_df.merge(prev_train, on='PetID', how='left')\n",
    "\n",
    "print(f\"Previous competition: {len(prev_hashes_df)} images hashed\")\n",
    "\n",
    "# Merge with current competition by hash\n",
    "print(\"\\nMerging competitions by image hash...\")\n",
    "df = train.merge(prev_hashes_df, on='hash', how='left', suffixes=('', '_prev'))\n",
    "\n",
    "n_matched = df['PetID'].notna().sum()\n",
    "print(f\"Matched images: {n_matched} ({n_matched/len(df)*100:.1f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4e96f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before merge: 0    0007de18844b0dbbb5e1f607da0606e0\n",
      "1    0009c66b9439883ba2750fb825e1d7db\n",
      "2    0013fd999caf9a3efe1352ca1b0d937e\n",
      "3    0018df346ac9c1d8413cfcc888ca8246\n",
      "4    001dc955e10590d3ca4673f034feeef2\n",
      "Name: Id, dtype: object\n",
      "After merge: 0    0007de18844b0dbbb5e1f607da0606e0\n",
      "1    0009c66b9439883ba2750fb825e1d7db\n",
      "2    0013fd999caf9a3efe1352ca1b0d937e\n",
      "3    0018df346ac9c1d8413cfcc888ca8246\n",
      "4    001dc955e10590d3ca4673f034feeef2\n",
      "Name: Id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Before merge:\", train['Id'].head())\n",
    "print(\"After merge:\", df['Id'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d534858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>...</th>\n",
       "      <th>Pawpularity</th>\n",
       "      <th>file</th>\n",
       "      <th>target_normalized</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>aspect</th>\n",
       "      <th>metadata</th>\n",
       "      <th>bin</th>\n",
       "      <th>fold</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>inputs/train/0007de18844b0dbbb5e1f607da0606e0.jpg</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-1.174489</td>\n",
       "      <td>-1.478196</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>fff0f0e7c3c1072f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>inputs/train/0009c66b9439883ba2750fb825e1d7db.jpg</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.830334</td>\n",
       "      <td>0.842205</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>a1e0317130383d0f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>inputs/train/0013fd999caf9a3efe1352ca1b0d937e.jpg</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.355090</td>\n",
       "      <td>-0.312445</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>fff3c3e0f0c08080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>inputs/train/0018df346ac9c1d8413cfcc888ca8246.jpg</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-1.174489</td>\n",
       "      <td>-1.478196</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ff7ff840c200c3e0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>inputs/train/001dc955e10590d3ca4673f034feeef2.jpg</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.355090</td>\n",
       "      <td>-0.978588</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>e0c04007bb097f7f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9907</th>\n",
       "      <td>ffbfa0383c34dc513c95560d6e1fdb57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>inputs/train/ffbfa0383c34dc513c95560d6e1fdb57.jpg</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.355090</td>\n",
       "      <td>-0.068192</td>\n",
       "      <td>1.221374</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>fff9c10307070f1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9908</th>\n",
       "      <td>ffcc8532d76436fc79e50eb2e5238e45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>inputs/train/ffcc8532d76436fc79e50eb2e5238e45.jpg</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.355090</td>\n",
       "      <td>-0.312445</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>ffe7c7e3e0e0f0d3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>ffdf2e8673a1da6fb80342fa3b119a20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>inputs/train/ffdf2e8673a1da6fb80342fa3b119a20.jpg</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.052798</td>\n",
       "      <td>-0.401264</td>\n",
       "      <td>1.287356</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>c08021207ef6feb8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>fff19e2ce11718548fa1c5d039a5192a</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>inputs/train/fff19e2ce11718548fa1c5d039a5192a.jpg</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.355090</td>\n",
       "      <td>-0.312445</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7f3fc1a1363e0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>fff8e47c766799c9e12f3cb3d66ad228</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>inputs/train/fff8e47c766799c9e12f3cb3d66ad228.jpg</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.355090</td>\n",
       "      <td>-0.978588</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>ffffc4ccb490000c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9912 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Id  Subject Focus  Eyes  Face  Near  \\\n",
       "0     0007de18844b0dbbb5e1f607da0606e0              0     1     1     1   \n",
       "1     0009c66b9439883ba2750fb825e1d7db              0     1     1     0   \n",
       "2     0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1   \n",
       "3     0018df346ac9c1d8413cfcc888ca8246              0     1     1     1   \n",
       "4     001dc955e10590d3ca4673f034feeef2              0     0     0     1   \n",
       "...                                ...            ...   ...   ...   ...   \n",
       "9907  ffbfa0383c34dc513c95560d6e1fdb57              0     0     0     1   \n",
       "9908  ffcc8532d76436fc79e50eb2e5238e45              0     1     1     1   \n",
       "9909  ffdf2e8673a1da6fb80342fa3b119a20              0     1     1     1   \n",
       "9910  fff19e2ce11718548fa1c5d039a5192a              0     1     1     1   \n",
       "9911  fff8e47c766799c9e12f3cb3d66ad228              0     1     1     1   \n",
       "\n",
       "      Action  Accessory  Group  Collage  Human  ...  Pawpularity  \\\n",
       "0          0          0      1        0      0  ...           63   \n",
       "1          0          0      0        0      0  ...           42   \n",
       "2          0          0      0        0      1  ...           28   \n",
       "3          0          0      0        0      0  ...           15   \n",
       "4          0          0      1        0      0  ...           72   \n",
       "...      ...        ...    ...      ...    ...  ...          ...   \n",
       "9907       0          0      0        0      0  ...           15   \n",
       "9908       0          0      0        0      0  ...           70   \n",
       "9909       0          0      0        0      1  ...           20   \n",
       "9910       0          0      0        0      1  ...           20   \n",
       "9911       0          0      0        0      0  ...           30   \n",
       "\n",
       "                                                   file  target_normalized  \\\n",
       "0     inputs/train/0007de18844b0dbbb5e1f607da0606e0.jpg               0.63   \n",
       "1     inputs/train/0009c66b9439883ba2750fb825e1d7db.jpg               0.42   \n",
       "2     inputs/train/0013fd999caf9a3efe1352ca1b0d937e.jpg               0.28   \n",
       "3     inputs/train/0018df346ac9c1d8413cfcc888ca8246.jpg               0.15   \n",
       "4     inputs/train/001dc955e10590d3ca4673f034feeef2.jpg               0.72   \n",
       "...                                                 ...                ...   \n",
       "9907  inputs/train/ffbfa0383c34dc513c95560d6e1fdb57.jpg               0.15   \n",
       "9908  inputs/train/ffcc8532d76436fc79e50eb2e5238e45.jpg               0.70   \n",
       "9909  inputs/train/ffdf2e8673a1da6fb80342fa3b119a20.jpg               0.20   \n",
       "9910  inputs/train/fff19e2ce11718548fa1c5d039a5192a.jpg               0.20   \n",
       "9911  inputs/train/fff8e47c766799c9e12f3cb3d66ad228.jpg               0.30   \n",
       "\n",
       "        height     width    aspect  \\\n",
       "0    -1.174489 -1.478196  1.777778   \n",
       "1    -0.830334  0.842205  0.750000   \n",
       "2     0.355090 -0.312445  1.333333   \n",
       "3    -1.174489 -1.478196  1.777778   \n",
       "4     0.355090 -0.978588  1.777778   \n",
       "...        ...       ...       ...   \n",
       "9907  0.355090 -0.068192  1.221374   \n",
       "9908  0.355090 -0.312445  1.333333   \n",
       "9909 -0.052798 -0.401264  1.287356   \n",
       "9910  0.355090 -0.312445  1.333333   \n",
       "9911  0.355090 -0.978588  1.777778   \n",
       "\n",
       "                                               metadata  bin  fold  \\\n",
       "0     [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...    8     4   \n",
       "1     [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    5     3   \n",
       "2     [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...    3     4   \n",
       "3     [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    1     0   \n",
       "4     [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   10     0   \n",
       "...                                                 ...  ...   ...   \n",
       "9907  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    1     2   \n",
       "9908  [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    9     3   \n",
       "9909  [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...    2     3   \n",
       "9910  [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...    2     1   \n",
       "9911  [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    4     2   \n",
       "\n",
       "                  hash  \n",
       "0     fff0f0e7c3c1072f  \n",
       "1     a1e0317130383d0f  \n",
       "2     fff3c3e0f0c08080  \n",
       "3     ff7ff840c200c3e0  \n",
       "4     e0c04007bb097f7f  \n",
       "...                ...  \n",
       "9907  fff9c10307070f1f  \n",
       "9908  ffe7c7e3e0e0f0d3  \n",
       "9909  c08021207ef6feb8  \n",
       "9910  7f3fc1a1363e0000  \n",
       "9911  ffffc4ccb490000c  \n",
       "\n",
       "[9912 rows x 23 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e1d626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PART 5: FEATURE ENGINEERING\n",
      "================================================================================\n",
      "NaN in pred1: 0\n",
      "NaN in pred2: 0\n",
      "Ensemble coefficients: pred1=0.0079, pred2=0.0019\n",
      "Stage 1 Ensemble RMSE: 18.6362\n",
      "\n",
      "Images with previous data: 218/9912\n",
      "\n",
      "Missing values before filling:\n",
      "  Age: 9694 (97.8%)\n",
      "  Breed1: 9694 (97.8%)\n",
      "  Gender: 9694 (97.8%)\n",
      "  Color3: 9694 (97.8%)\n",
      "  FurLength: 9694 (97.8%)\n",
      "  Vaccinated: 9694 (97.8%)\n",
      "  Quantity: 9694 (97.8%)\n",
      "  Fee: 9694 (97.8%)\n",
      "  State: 9694 (97.8%)\n",
      "  PhotoAmt: 9694 (97.8%)\n",
      "  AdoptionSpeed: 9694 (97.8%)\n",
      "\n",
      "Missing values after filling:\n",
      "  All missing values handled âœ“\n",
      "\n",
      "Data types:\n",
      "  Blur: int64\n",
      "  Eyes: int64\n",
      "  pred: float64\n",
      "  has_prev_data: int64\n",
      "  Age: float64\n",
      "  Breed1: float64\n",
      "  Gender: float64\n",
      "  Color3: float64\n",
      "  FurLength: float64\n",
      "  Vaccinated: float64\n",
      "  Quantity: float64\n",
      "  Fee: float64\n",
      "  State: float64\n",
      "  PhotoAmt: float64\n",
      "  AdoptionSpeed: float64\n",
      "\n",
      "Total features for Stage 2: 15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# PART 5: FEATURE ENGINEERING\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PART 5: FEATURE ENGINEERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Add Stage 1 OOF predictions to dataframe\n",
    "df['pred1'] = stage1_oofs[stage1_models_config[0]['name']]\n",
    "df['pred2'] = stage1_oofs[stage1_models_config[1]['name']]\n",
    "\n",
    "# Check for any NaN in predictions\n",
    "print(f\"NaN in pred1: {df['pred1'].isna().sum()}\")\n",
    "print(f\"NaN in pred2: {df['pred2'].isna().sum()}\")\n",
    "\n",
    "# Find optimal weights using least squares\n",
    "\n",
    "valid_mask = df['pred1'].notna() & df['pred2'].notna()\n",
    "coef = np.linalg.lstsq(\n",
    "    df.loc[valid_mask, ['pred1', 'pred2']].values, \n",
    "    df.loc[valid_mask, 'Pawpularity'].values / 100,\n",
    "    rcond=None\n",
    ")[0]\n",
    "\n",
    "print(f\"Ensemble coefficients: pred1={coef[0]:.4f}, pred2={coef[1]:.4f}\")\n",
    "\n",
    "#  weighted ensemble\n",
    "df['pred'] = np.dot(df[['pred1', 'pred2']].values, coef)\n",
    "\n",
    "# Clip predictions to valid range [0.01, 1.0]\n",
    "df['pred'] = df['pred'].clip(0.01, 1.0)\n",
    "\n",
    "# Stage 1 ensemble RMSE\n",
    "stage1_rmse = np.sqrt(np.mean((df['Pawpularity'].values - df['pred'].values * 100) ** 2))\n",
    "print(f\"Stage 1 Ensemble RMSE: {stage1_rmse:.4f}\")\n",
    "\n",
    "# Text features from previous competition\n",
    "df['len_desc'] = df['Description'].fillna('').map(len)\n",
    "df['len_name'] = df['Name'].fillna('').map(len)\n",
    "\n",
    "# Binary flag for whether image has previous competition data\n",
    "df['has_prev_data'] = df['PetID'].notna().astype(int)\n",
    "\n",
    "print(f\"\\nImages with previous data: {df['has_prev_data'].sum()}/{len(df)}\")\n",
    "\n",
    "# Create feature list\n",
    "COL_FEATURES = [\n",
    "    # Current competition\n",
    "    'Blur', 'Eyes',\n",
    "    \n",
    "    # Stage 1 ensemble\n",
    "    'pred',\n",
    "    \n",
    "    # Binary flag\n",
    "    'has_prev_data',\n",
    "    \n",
    "    # Previous competition (selected features)\n",
    "    'Age', 'Breed1', 'Gender', 'Color3', 'FurLength',\n",
    "    'Vaccinated', 'Quantity', 'Fee', 'State', 'PhotoAmt', 'AdoptionSpeed'\n",
    "]\n",
    "\n",
    "# Check for missing values BEFORE filling\n",
    "print(\"\\nMissing values before filling:\")\n",
    "for col in COL_FEATURES:\n",
    "    if col in df.columns:\n",
    "        n_missing = df[col].isna().sum()\n",
    "        if n_missing > 0:\n",
    "            print(f\"  {col}: {n_missing} ({n_missing/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Fill missing values with -1 (for images not in previous competition)\n",
    "for col in COL_FEATURES:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(-1)\n",
    "    else:\n",
    "        print(f\"WARNING: {col} not found in dataframe!\")\n",
    "        df[col] = -1  # Create column with -1 if not exists\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(\"\\nMissing values after filling:\")\n",
    "n_missing_total = df[COL_FEATURES].isna().sum().sum()\n",
    "if n_missing_total > 0:\n",
    "    print(f\"  WARNING: Still have {n_missing_total} missing values!\")\n",
    "    print(df[COL_FEATURES].isna().sum())\n",
    "else:\n",
    "    print(\"  All missing values handled \")\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "for col in COL_FEATURES:\n",
    "    print(f\"  {col}: {df[col].dtype}\")\n",
    "\n",
    "# Convert all to float for LGBM\n",
    "for col in COL_FEATURES:\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "print(f\"\\nTotal features for Stage 2: {len(COL_FEATURES)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de41b6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 6: TRAINING STAGE 2 LGBM\n",
      "\n",
      "Final data validation before LGBM training:\n",
      "  Total samples: 9912\n",
      "  Features shape: (9912, 15)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# PART 6: TRAIN STAGE 2 LGBM\n",
    "\n",
    "\n",
    "\n",
    "print(\"PART 6: TRAINING STAGE 2 LGBM\")\n",
    "\n",
    "\n",
    "# FINAL DATA VALIDATION BEFORE TRAINING\n",
    "print(\"\\nFinal data validation before LGBM training:\")\n",
    "print(f\"  Total samples: {len(df)}\")\n",
    "print(f\"  Features shape: {df[COL_FEATURES].shape}\")\n",
    "\n",
    "# Check for any remaining issues\n",
    "X_check = df[COL_FEATURES].values\n",
    "y_check = df['Pawpularity'].values\n",
    "\n",
    "\n",
    "\n",
    "def rmse_metric(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    loss = np.sqrt(((labels - preds.clip(0.01, 1)) ** 2).mean()) * 100\n",
    "    return 'rmse', loss, False\n",
    "\n",
    "\n",
    "lgb_params = {\n",
    "    'objective': 'tweedie',\n",
    "    'tweedie_variance_power': 1.2,\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 1,\n",
    "    'num_iterations': 10000,\n",
    "    'seed': 114,\n",
    "    'metric': 'None',\n",
    "    'learning_rate': 0.05,\n",
    "    'lambda_l2': 1,\n",
    "    'min_child_samples': 140,\n",
    "    'num_leaves': 7,\n",
    "    'feature_fraction': 0.7,\n",
    "    'min_gain_to_split': 0.02,\n",
    "}\n",
    "\n",
    "\n",
    "def train_fold_lgb(fold, param):\n",
    "    X_train = df.loc[df['fold'] != fold, COL_FEATURES]\n",
    "    y_train = df.loc[df['fold'] != fold, 'Pawpularity'].values / 100\n",
    "    \n",
    "    X_valid = df.loc[df['fold'] == fold, COL_FEATURES]\n",
    "    y_valid = df.loc[df['fold'] == fold, 'Pawpularity'].values / 100\n",
    "    \n",
    "    # Check for any NaN or inf values\n",
    "    if np.isnan(X_train.values).any() or np.isinf(X_train.values).any():\n",
    "        print(\"WARNING: NaN or Inf in training data!\")\n",
    "        X_train = X_train.fillna(-1).replace([np.inf, -np.inf], -1)\n",
    "    \n",
    "    if np.isnan(X_valid.values).any() or np.isinf(X_valid.values).any():\n",
    "        print(\"WARNING: NaN or Inf in validation data!\")\n",
    "        X_valid = X_valid.fillna(-1).replace([np.inf, -np.inf], -1)\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        param,\n",
    "        train_data,\n",
    "        valid_sets=valid_data,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=100),\n",
    "            lgb.log_evaluation(100)\n",
    "        ],\n",
    "        feval=rmse_metric\n",
    "    )\n",
    "    \n",
    "    val_preds = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    return model, val_preds, y_valid\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03880a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 18.7843\n",
      "[200]\tvalid_0's rmse: 18.7991\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's rmse: 18.7775\n",
      "Training Fold 2/5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 18.7194\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's rmse: 18.7186\n",
      "Training Fold 3/5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 18.2373\n",
      "[200]\tvalid_0's rmse: 18.2434\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's rmse: 18.2341\n",
      "Training Fold 4/5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 18.5756\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's rmse: 18.5002\n",
      "Training Fold 5/5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 19.1112\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's rmse: 19.1071\n",
      "Stage 2 LGBM CV RMSE (all folds combined): 18.6722\n"
     ]
    }
   ],
   "source": [
    "# Store all validation predictions and labels\n",
    "all_val_preds = []\n",
    "all_val_labels = []\n",
    "\n",
    "for fold in range(5):\n",
    "   \n",
    "    print(f\"Training Fold {fold+1}/5\")\n",
    "    \n",
    "    model, val_preds, val_labels = train_fold_lgb(fold, lgb_params)\n",
    "    \n",
    "    # Append fold predictions and labels\n",
    "    all_val_preds.append(val_preds)\n",
    "    all_val_labels.append(val_labels)\n",
    "\n",
    "# Concatenate all folds\n",
    "all_val_preds = np.concatenate(all_val_preds)\n",
    "all_val_labels = np.concatenate(all_val_labels)\n",
    "\n",
    "# Compute CV RMSE over all validation samples\n",
    "cv_rmse = np.sqrt(((all_val_preds - all_val_labels) ** 2).mean()) * 100\n",
    "\n",
    "print(f\"Stage 2 LGBM CV RMSE (all folds combined): {cv_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b091603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAPIDS (WSL)",
   "language": "python",
   "name": "rapids-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
