{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70093d66",
   "metadata": {},
   "source": [
    "This is the minimal implementation of this solution of Petfinder Pawpularity, The number of folds, epochs and other models selection are reduced due to longer time training, but the overall strategy is demonstrated.\n",
    "### Overview\n",
    "The 3rd-place solution used many different deep learning models to predict Pawpularity scores, including Swin Large, ViT Large, and CaiT. For some models, they treated the problem as a classification task over 101 classes (0–100 Pawpularity) and then converted the predicted probabilities back to a continuous score using a weighted sum. They also added three SVR (Support Vector Regressor) heads to some models, which helps create diversity in the predictions and reduces overfitting by giving slightly different perspectives on the same features. In the second stage, all predictions from the first-stage models and SVR heads were combined using linear regression, which learns the best weights for each model’s output to produce a final, more accurate prediction.\n",
    "### Strengths\n",
    "This strategy works well because using the classification trick allows the models to benefit from cross-entropy loss and mixup augmentation, which improves generalization. Multiple SVR heads increase prediction diversity, and linear regression stacking combines all outputs optimally to reduce error. Overall, using many models with diverse predictions and combining them carefully through stacking gives better performance than relying on a single model.\n",
    "### Differences to our model\n",
    "Unlike our single image model, they used different models with multiple heads to diversify to diversify evaluaiton. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c5d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import timm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import gc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from cuml.svm import SVR # Using cuml for GPU-accelerated SVR\n",
    "import albumentations as A\n",
    "from torch import nn\n",
    "import joblib\n",
    "\n",
    "# Set up device and file paths\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BASE_PATH = \"inputs/\"\n",
    "OOF_SAVE_DIR = \"top3_with_metadata\" # \n",
    "os.makedirs(OOF_SAVE_DIR, exist_ok=True) \n",
    "\n",
    "# --- Metadata Column Names ---\n",
    "METADATA_COLS = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', \n",
    "                 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n",
    "METADATA_DIM = len(METADATA_COLS) # Should be 12\n",
    "\n",
    "# --- 1. Data Loading, Metadata Processing, and Stratified Folds ---\n",
    "train = pd.read_csv(BASE_PATH + 'train.csv') \n",
    "train['file'] = train['Id'].apply(lambda x: f'{BASE_PATH}train/{x}.jpg')\n",
    "\n",
    "# Standardize the Pawpularity target (0-1) and extract metadata features\n",
    "train['target_normalized'] = train['Pawpularity'] / 100.0\n",
    "train['metadata'] = train[METADATA_COLS].values.tolist() # Store metadata as a list/array per row\n",
    "\n",
    "# Stratified folds (5-fold )\n",
    "train['bin'] = (train['Pawpularity'] // 5).round()\n",
    "train['fold'] = -1\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "for i, (_, val_idx) in enumerate(skf.split(train, train['bin'])):\n",
    "    train.loc[val_idx, 'fold'] = i\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1299de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "      <th>file</th>\n",
       "      <th>target_normalized</th>\n",
       "      <th>metadata</th>\n",
       "      <th>bin</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>inputs/train/0007de18844b0dbbb5e1f607da0606e0.jpg</td>\n",
       "      <td>0.63</td>\n",
       "      <td>[0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>inputs/train/0009c66b9439883ba2750fb825e1d7db.jpg</td>\n",
       "      <td>0.42</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>inputs/train/0013fd999caf9a3efe1352ca1b0d937e.jpg</td>\n",
       "      <td>0.28</td>\n",
       "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>inputs/train/0018df346ac9c1d8413cfcc888ca8246.jpg</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>inputs/train/001dc955e10590d3ca4673f034feeef2.jpg</td>\n",
       "      <td>0.72</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "2  0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
       "3  0018df346ac9c1d8413cfcc888ca8246              0     1     1     1       0   \n",
       "4  001dc955e10590d3ca4673f034feeef2              0     0     0     1       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  \\\n",
       "0          0      1        0      0          0     0     0           63   \n",
       "1          0      0        0      0          0     0     0           42   \n",
       "2          0      0        0      1          1     0     0           28   \n",
       "3          0      0        0      0          0     0     0           15   \n",
       "4          0      1        0      0          0     0     0           72   \n",
       "\n",
       "                                                file  target_normalized  \\\n",
       "0  inputs/train/0007de18844b0dbbb5e1f607da0606e0.jpg               0.63   \n",
       "1  inputs/train/0009c66b9439883ba2750fb825e1d7db.jpg               0.42   \n",
       "2  inputs/train/0013fd999caf9a3efe1352ca1b0d937e.jpg               0.28   \n",
       "3  inputs/train/0018df346ac9c1d8413cfcc888ca8246.jpg               0.15   \n",
       "4  inputs/train/001dc955e10590d3ca4673f034feeef2.jpg               0.72   \n",
       "\n",
       "                               metadata  bin  fold  \n",
       "0  [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0]   12     0  \n",
       "1  [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]    8     1  \n",
       "2  [0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0]    5     2  \n",
       "3  [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]    3     4  \n",
       "4  [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0]   14     0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef9329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Dataset and Transforms (Updated for Metadata) ---\n",
    "class PetDataset(Dataset):\n",
    "    def __init__(self, image_paths, targets, metadata, transform=None, target_dtype=torch.float): # Added metadata\n",
    "        self.image_paths = image_paths\n",
    "        self.targets = targets \n",
    "        self.metadata = metadata # New metadata array\n",
    "        self.transform = transform\n",
    "        self.target_dtype = target_dtype\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        \n",
    "        image = image / 255.0\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        \n",
    "        return {\n",
    "            'image': torch.tensor(image, dtype=torch.float),\n",
    "            'metadata': torch.tensor(self.metadata[idx], dtype=torch.float), # Return metadata as float tensor\n",
    "            'target': torch.tensor(self.targets[idx], dtype=self.target_dtype) \n",
    "        }\n",
    "\n",
    "def get_transforms(img_size=224, aug_type='light', is_train=True):\n",
    "    #  transforms \n",
    "    if is_train:\n",
    "        return A.Compose([\n",
    "            A.Resize(img_size, img_size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Rotate(limit=15, p=0.5),\n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([A.Resize(img_size, img_size)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b95d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Model Definition (Updated for Metadata) ---\n",
    "class PetModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes, metadata_dim, pretrained=True): # Added metadata_dim\n",
    "        super().__init__()\n",
    "        # 1. Image Backbone (without the final linear head)\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=0) \n",
    "        # Get the feature dimension from the backbone\n",
    "        self.feature_dim = self.model.num_features\n",
    "        \n",
    "        # 2. Final Head (takes concatenated features)\n",
    "        total_input_dim = self.feature_dim + metadata_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.final_head = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(total_input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes) # Final output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_img, x_meta): # Accepts both image and metadata\n",
    "       \n",
    "        img_features = self.model(x_img)\n",
    "        combined_features = torch.cat([img_features, x_meta], dim=1)\n",
    "        out = self.final_head(combined_features)\n",
    "        \n",
    "     \n",
    "        if self.num_classes == 1:\n",
    "            return out.squeeze(-1)  # Always squeeze for BCE\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ece32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 4. Training Function with Dual Loss Logic (Updated with RMSE printing and Early Stopping) ---\n",
    "def train_dl_model(model_name, train_df, loss_type, n_epochs, batch_size, \n",
    "                   img_size, lr, save_dir):\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    n_folds = 5\n",
    "    oof_preds = np.zeros(len(train_df), dtype=float)\n",
    "\n",
    "    # Define Early Stopping parameters\n",
    "    max_patience = 3 \n",
    "\n",
    "    # Determine loss and class count\n",
    "    if loss_type == 'CE':\n",
    "        num_classes = 100\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        target_dtype = torch.long\n",
    "    elif loss_type == 'BCE':\n",
    "        num_classes = 1\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        target_dtype = torch.float\n",
    "    else:\n",
    "        raise ValueError(\"loss_type must be 'CE' or 'BCE'\")\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Model: {model_name} ({loss_type}) | Fold {fold+1}/{n_folds} (With Metadata)\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # --- Data Split and Target Preparation ---\n",
    "        tr_ind = train_df['fold'] != fold\n",
    "        val_ind = train_df['fold'] == fold\n",
    "        \n",
    "        tr_paths = train_df.loc[tr_ind, 'file'].values\n",
    "        val_paths = train_df.loc[val_ind, 'file'].values\n",
    "        val_targets_original = train_df.loc[val_ind, 'Pawpularity'].values \n",
    "        \n",
    "        tr_metadata = np.stack(train_df.loc[tr_ind, 'metadata'].values)\n",
    "        val_metadata = np.stack(train_df.loc[val_ind, 'metadata'].values)\n",
    "        \n",
    "        # Targets specific to Loss Type\n",
    "        if loss_type == 'BCE':\n",
    "            tr_targets = train_df.loc[tr_ind, 'target_normalized'].values\n",
    "            val_targets_normalized = train_df.loc[val_ind, 'target_normalized'].values\n",
    "        elif loss_type == 'CE':\n",
    "            tr_targets = (train_df.loc[tr_ind, 'Pawpularity'].values - 1).astype(int)\n",
    "            val_targets_normalized = (train_df.loc[val_ind, 'Pawpularity'].values - 1).astype(int)\n",
    "        \n",
    "        # Create datasets (passing metadata)\n",
    "        train_dataset = PetDataset(tr_paths, tr_targets, tr_metadata,\n",
    "                                   transform=get_transforms(img_size, 'light', is_train=True),\n",
    "                                   target_dtype=target_dtype)\n",
    "        val_dataset = PetDataset(val_paths, val_targets_normalized, val_metadata,\n",
    "                                 transform=get_transforms(img_size, 'light', is_train=False),\n",
    "                                 target_dtype=target_dtype)\n",
    "\n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size*2, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "        # Model, optimizer, scheduler (passing metadata_dim)\n",
    "        #  METADATA_DIM needs to be defined in the global scope!\n",
    "        model = PetModel(model_name, num_classes=num_classes, metadata_dim=METADATA_DIM, pretrained=True).to(device)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=3, T_mult=1)\n",
    "\n",
    "        best_val_rmse = float('inf')\n",
    "        best_val_preds = None\n",
    "        patience = 0 # Initialize patience\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            # Training Loop\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            train_count = 0\n",
    "            for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs} [Train]\"):\n",
    "                imgs = batch['image'].to(device)\n",
    "                metas = batch['metadata'].to(device) \n",
    "                tgts = batch['target'].to(device) \n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                logits = model(imgs, metas)\n",
    "                loss = criterion(logits, tgts) \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item() * len(imgs)\n",
    "                train_count += len(imgs)\n",
    "            \n",
    "            avg_train_loss = train_loss / train_count\n",
    "            scheduler.step()\n",
    "\n",
    "            # Validation Loop\n",
    "            model.eval()\n",
    "            val_preds = []\n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{n_epochs} [Valid]\"):\n",
    "                    imgs = batch['image'].to(device)\n",
    "                    metas = batch['metadata'].to(device) \n",
    "                    logits = model(imgs, metas) \n",
    "                    \n",
    "                    if loss_type == 'BCE':\n",
    "                        scaled = torch.sigmoid(logits) * 100.0\n",
    "                    elif loss_type == 'CE':\n",
    "                        predicted_classes = torch.argmax(logits, dim=1) \n",
    "                        scaled = (predicted_classes.float() + 1.0)\n",
    "                        \n",
    "                    val_preds.extend(scaled.cpu().numpy())\n",
    "\n",
    "            val_preds = np.clip(np.array(val_preds), 1, 100)\n",
    "            val_rmse = np.sqrt(np.mean((val_targets_original - val_preds) ** 2))\n",
    "            \n",
    "            # --- Per-Epoch RMSE and Early Stopping Logic ---\n",
    "            \n",
    "            # Print current epoch results\n",
    "            print(f\"   Epoch {epoch+1}/{n_epochs} | Train Loss: {avg_train_loss:.4f} | Val RMSE: {val_rmse:.4f}\", end='')\n",
    "\n",
    "            if val_rmse < best_val_rmse:\n",
    "                best_val_rmse = val_rmse\n",
    "                best_val_preds = val_preds.copy()\n",
    "                \n",
    "                # Save best model weights \n",
    "                torch.save(model.state_dict(), os.path.join(save_dir, f\"{model_name}_{loss_type}_fold{fold}.pth\"))\n",
    "                patience = 0  # Reset patience on improvement\n",
    "                print(\" -> **BEST** model saved!\")\n",
    "            else:\n",
    "                patience += 1 # Increment patience when no improvement\n",
    "                print(f\" | Patience: {patience}/{max_patience}\")\n",
    "\n",
    "                if patience >= max_patience:\n",
    "                    print(f\"\\n   Early stopping triggered (patience={max_patience})\")\n",
    "                    break # Stop training for this fold\n",
    "\n",
    "        # Store best predictions for this fold\n",
    "        oof_preds[val_ind.values] = best_val_preds\n",
    "        print(f\"\\nFold {fold+1} Complete | Final Best Val RMSE: {best_val_rmse:.4f}\")\n",
    "        \n",
    "        del model, optimizer, scheduler, train_dataset, val_dataset, train_loader, val_loader\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    # Calculate overall OOF RMSE and save\n",
    "    overall_rmse = np.sqrt(np.mean((train_df['Pawpularity'].values - oof_preds) ** 2))\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{model_name} ({loss_type}) - Overall OOF RMSE: {overall_rmse:.4f}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    np.save(os.path.join(save_dir, f\"oof_{model_name}_{loss_type}.npy\"), oof_preds)\n",
    "    return oof_preds, overall_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8bab11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 1: TRAINING DL MODELS & GENERATING OOFs WITH METADATA\n",
      "\n",
      "======================================================================\n",
      "Model: swin_base_patch4_window7_224 (BCE) | Fold 1/5 (With Metadata)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Train]: 100%|██████████| 496/496 [03:02<00:00,  2.72it/s]\n",
      "Epoch 1/3 [Valid]: 100%|██████████| 62/62 [00:14<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 0.6670 | Val RMSE: 20.6660 -> **BEST** model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [Train]: 100%|██████████| 496/496 [03:00<00:00,  2.74it/s]\n",
      "Epoch 2/3 [Valid]: 100%|██████████| 62/62 [00:15<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 0.6652 | Val RMSE: 20.6164 -> **BEST** model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [Train]: 100%|██████████| 496/496 [03:01<00:00,  2.74it/s]\n",
      "Epoch 3/3 [Valid]: 100%|██████████| 62/62 [00:15<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 0.6624 | Val RMSE: 18.9285 -> **BEST** model saved!\n",
      "\n",
      "Fold 1 Complete | Final Best Val RMSE: 18.9285\n",
      "\n",
      "======================================================================\n",
      "Model: swin_base_patch4_window7_224 (BCE) | Fold 2/5 (With Metadata)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Train]: 100%|██████████| 496/496 [03:02<00:00,  2.72it/s]\n",
      "Epoch 1/3 [Valid]: 100%|██████████| 62/62 [00:14<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 0.6642 | Val RMSE: 20.6492 -> **BEST** model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [Train]: 100%|██████████| 496/496 [03:01<00:00,  2.73it/s]\n",
      "Epoch 2/3 [Valid]: 100%|██████████| 62/62 [00:15<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 0.6575 | Val RMSE: 19.5457 -> **BEST** model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [Train]: 100%|██████████| 496/496 [03:01<00:00,  2.73it/s]\n",
      "Epoch 3/3 [Valid]: 100%|██████████| 62/62 [00:15<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 0.6406 | Val RMSE: 18.4695 -> **BEST** model saved!\n",
      "\n",
      "Fold 2 Complete | Final Best Val RMSE: 18.4695\n",
      "\n",
      "======================================================================\n",
      "Model: swin_base_patch4_window7_224 (BCE) | Fold 3/5 (With Metadata)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Train]: 100%|██████████| 496/496 [03:02<00:00,  2.72it/s]\n",
      "Epoch 1/3 [Valid]: 100%|██████████| 62/62 [00:14<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 0.6669 | Val RMSE: 20.0028 -> **BEST** model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [Train]: 100%|██████████| 496/496 [03:02<00:00,  2.71it/s]\n",
      "Epoch 2/3 [Valid]: 100%|██████████| 62/62 [00:14<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 0.6593 | Val RMSE: 19.8288 -> **BEST** model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [Train]: 100%|██████████| 496/496 [03:01<00:00,  2.73it/s]\n",
      "Epoch 3/3 [Valid]: 100%|██████████| 62/62 [00:15<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 0.6461 | Val RMSE: 18.6921 -> **BEST** model saved!\n",
      "\n",
      "Fold 3 Complete | Final Best Val RMSE: 18.6921\n",
      "\n",
      "======================================================================\n",
      "Model: swin_base_patch4_window7_224 (BCE) | Fold 4/5 (With Metadata)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Train]: 100%|██████████| 496/496 [03:01<00:00,  2.73it/s]\n",
      "Epoch 1/3 [Valid]: 100%|██████████| 62/62 [00:14<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 0.6672 | Val RMSE: 20.8869 -> **BEST** model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [Train]: 100%|██████████| 496/496 [03:01<00:00,  2.73it/s]\n",
      "Epoch 2/3 [Valid]: 100%|██████████| 62/62 [00:14<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 0.6660 | Val RMSE: 20.6553 -> **BEST** model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [Train]: 100%|██████████| 496/496 [03:03<00:00,  2.71it/s]\n",
      "Epoch 3/3 [Valid]: 100%|██████████| 62/62 [00:15<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 0.6643 | Val RMSE: 19.6217 -> **BEST** model saved!\n",
      "\n",
      "Fold 4 Complete | Final Best Val RMSE: 19.6217\n",
      "\n",
      "======================================================================\n",
      "Model: swin_base_patch4_window7_224 (BCE) | Fold 5/5 (With Metadata)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Train]: 100%|██████████| 496/496 [03:02<00:00,  2.72it/s]\n",
      "Epoch 1/3 [Valid]: 100%|██████████| 62/62 [00:15<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 0.6674 | Val RMSE: 20.6180 -> **BEST** model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [Train]: 100%|██████████| 496/496 [03:01<00:00,  2.73it/s]\n",
      "Epoch 2/3 [Valid]: 100%|██████████| 62/62 [00:14<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 0.6661 | Val RMSE: 20.6204 | Patience: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [Train]: 100%|██████████| 496/496 [03:01<00:00,  2.73it/s]\n",
      "Epoch 3/3 [Valid]: 100%|██████████| 62/62 [00:14<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 0.6652 | Val RMSE: 20.6768 | Patience: 2/3\n",
      "\n",
      "Fold 5 Complete | Final Best Val RMSE: 20.6180\n",
      "\n",
      "======================================================================\n",
      "swin_base_patch4_window7_224 (BCE) - Overall OOF RMSE: 19.2816\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Model: vit_base_patch16_384 (CE) | Fold 1/5 (With Metadata)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Train]: 100%|██████████| 496/496 [08:27<00:00,  1.02s/it]\n",
      "Epoch 1/3 [Valid]: 100%|██████████| 62/62 [00:42<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 4.3887 | Val RMSE: 31.8708 -> **BEST** model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [Train]: 100%|██████████| 496/496 [08:24<00:00,  1.02s/it]\n",
      "Epoch 2/3 [Valid]: 100%|██████████| 62/62 [00:41<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 4.2860 | Val RMSE: 21.7510 -> **BEST** model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [Train]: 100%|██████████| 496/496 [08:25<00:00,  1.02s/it]\n",
      "Epoch 3/3 [Valid]: 100%|██████████| 62/62 [00:42<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 4.2658 | Val RMSE: 23.3490 | Patience: 1/3\n",
      "\n",
      "Fold 1 Complete | Final Best Val RMSE: 21.7510\n",
      "\n",
      "======================================================================\n",
      "Model: vit_base_patch16_384 (CE) | Fold 2/5 (With Metadata)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Train]: 100%|██████████| 496/496 [08:25<00:00,  1.02s/it]\n",
      "Epoch 1/3 [Valid]: 100%|██████████| 62/62 [00:42<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 4.3786 | Val RMSE: 22.1323 -> **BEST** model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [Train]: 100%|██████████| 496/496 [08:25<00:00,  1.02s/it]\n",
      "Epoch 2/3 [Valid]: 100%|██████████| 62/62 [00:41<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 4.2920 | Val RMSE: 23.3117 | Patience: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [Train]: 100%|██████████| 496/496 [08:25<00:00,  1.02s/it]\n",
      "Epoch 3/3 [Valid]: 100%|██████████| 62/62 [00:42<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 4.2648 | Val RMSE: 22.4715 | Patience: 2/3\n",
      "\n",
      "Fold 2 Complete | Final Best Val RMSE: 22.1323\n",
      "\n",
      "======================================================================\n",
      "Model: vit_base_patch16_384 (CE) | Fold 3/5 (With Metadata)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Train]: 100%|██████████| 496/496 [08:27<00:00,  1.02s/it]\n",
      "Epoch 1/3 [Valid]: 100%|██████████| 62/62 [00:42<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 4.3996 | Val RMSE: 22.1579 -> **BEST** model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [Train]: 100%|██████████| 496/496 [08:26<00:00,  1.02s/it]\n",
      "Epoch 2/3 [Valid]: 100%|██████████| 62/62 [00:42<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 4.2977 | Val RMSE: 21.4306 -> **BEST** model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [Train]: 100%|██████████| 496/496 [08:26<00:00,  1.02s/it]\n",
      "Epoch 3/3 [Valid]: 100%|██████████| 62/62 [00:42<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 4.2638 | Val RMSE: 22.0135 | Patience: 1/3\n",
      "\n",
      "Fold 3 Complete | Final Best Val RMSE: 21.4306\n",
      "\n",
      "======================================================================\n",
      "Model: vit_base_patch16_384 (CE) | Fold 4/5 (With Metadata)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Train]: 100%|██████████| 496/496 [08:27<00:00,  1.02s/it]\n",
      "Epoch 1/3 [Valid]: 100%|██████████| 62/62 [00:42<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 4.3789 | Val RMSE: 64.9547 -> **BEST** model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [Train]: 100%|██████████| 496/496 [08:26<00:00,  1.02s/it]\n",
      "Epoch 2/3 [Valid]: 100%|██████████| 62/62 [00:42<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 4.2826 | Val RMSE: 22.9059 -> **BEST** model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [Train]: 100%|██████████| 496/496 [08:27<00:00,  1.02s/it]\n",
      "Epoch 3/3 [Valid]: 100%|██████████| 62/62 [00:42<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 4.2638 | Val RMSE: 24.3373 | Patience: 1/3\n",
      "\n",
      "Fold 4 Complete | Final Best Val RMSE: 22.9059\n",
      "\n",
      "======================================================================\n",
      "Model: vit_base_patch16_384 (CE) | Fold 5/5 (With Metadata)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Train]: 100%|██████████| 496/496 [08:27<00:00,  1.02s/it]\n",
      "Epoch 1/3 [Valid]: 100%|██████████| 62/62 [00:42<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/3 | Train Loss: 4.3747 | Val RMSE: 23.3867 -> **BEST** model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [Train]: 100%|██████████| 496/496 [08:27<00:00,  1.02s/it]\n",
      "Epoch 2/3 [Valid]: 100%|██████████| 62/62 [00:41<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2/3 | Train Loss: 4.2860 | Val RMSE: 22.3565 -> **BEST** model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [Train]: 100%|██████████| 496/496 [08:25<00:00,  1.02s/it]\n",
      "Epoch 3/3 [Valid]: 100%|██████████| 62/62 [00:42<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3/3 | Train Loss: 4.2590 | Val RMSE: 22.1567 -> **BEST** model saved!\n",
      "\n",
      "Fold 5 Complete | Final Best Val RMSE: 22.1567\n",
      "\n",
      "======================================================================\n",
      "vit_base_patch16_384 (CE) - Overall OOF RMSE: 22.0808\n",
      "======================================================================\n",
      "\n",
      "PART 2: 2ND STAGE ENSEMBLE (SVR + LINEAR REGRESSION)\n",
      "[W] [22:40:31.292858] SVR with the linear kernel can be much faster using the specialized solver provided by LinearSVR. Consider switching to LinearSVR if tranining takes too long.\n",
      "SVR1 OOF RMSE: 19.6120\n",
      "SVR2 OOF RMSE: 19.5875\n",
      "\n",
      "######################################################################\n",
      "Final 2nd Stage Ensemble OOF RMSE : 19.2612\n",
      "######################################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['top3_with_metadata/svr2_model.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 5. Configuration and Execution ---\n",
    "\n",
    "print(\"PART 1: TRAINING DL MODELS & GENERATING OOFs WITH METADATA\")\n",
    "\n",
    "# Define the two models\n",
    "dl_models_config = [\n",
    "    \n",
    "    # Model 1: Simple Regression (BCE Loss)\n",
    "    {\"name\": \"swin_base_patch4_window7_224\", \"size\": 224, \"loss_type\": \"BCE\", \"lr\": 1e-4, \"epochs\": 3, \"batch_size\": 16},\n",
    "     # Model 2: Multi-Class Classification (CE Loss)\n",
    "    {\"name\": \"vit_base_patch16_384\", \"size\": 384, \"loss_type\": \"CE\", \"lr\": 5e-5, \"epochs\": 3, \"batch_size\": 16},\n",
    "   \n",
    "  \n",
    "]\n",
    "\n",
    "cnn_oofs = {}\n",
    "\n",
    "for cfg in dl_models_config:\n",
    "    oof, rmse = train_dl_model(\n",
    "        model_name=cfg[\"name\"],\n",
    "        train_df=train,\n",
    "        loss_type=cfg[\"loss_type\"],\n",
    "        n_epochs=cfg[\"epochs\"],\n",
    "        batch_size=cfg[\"batch_size\"],\n",
    "        img_size=cfg[\"size\"],\n",
    "        lr=cfg[\"lr\"],\n",
    "        save_dir=OOF_SAVE_DIR\n",
    "    )\n",
    "    cnn_oofs[f\"{cfg['name']}_{cfg['loss_type']}\"] = oof\n",
    "\n",
    "# --- 6. 2nd Stage Ensemble: SVR Heads and Linear Regression  ---\n",
    "\n",
    "print(\"PART 2: 2ND STAGE ENSEMBLE (SVR + LINEAR REGRESSION)\")\n",
    "\n",
    "# Retrieve OOF predictions\n",
    "OOF_BCE = cnn_oofs[f\"{dl_models_config[0]['name']}_{dl_models_config[0]['loss_type']}\"]\n",
    "OOF_CE = cnn_oofs[f\"{dl_models_config[1]['name']}_{dl_models_config[1]['loss_type']}\"]\n",
    "targets = train['Pawpularity'].values\n",
    "\n",
    "# --- 6A. Train Two SVR Heads (on BCE Model OOFs) ---\n",
    "# ... (SVR training logic here)\n",
    "OOF_BCE_reshaped = OOF_BCE.reshape(-1, 1)\n",
    "\n",
    "svr1 = SVR(kernel='rbf', C=1.0, epsilon=0.1) \n",
    "svr1.fit(OOF_BCE_reshaped, targets)\n",
    "OOF_SVR1 = svr1.predict(OOF_BCE_reshaped)\n",
    "\n",
    "svr2 = SVR(kernel='linear', C=0.5, epsilon=0.05) \n",
    "svr2.fit(OOF_BCE_reshaped, targets)\n",
    "OOF_SVR2 = svr2.predict(OOF_BCE_reshaped)\n",
    "\n",
    "print(f\"SVR1 OOF RMSE: {np.sqrt(np.mean((targets - OOF_SVR1) ** 2)):.4f}\")\n",
    "print(f\"SVR2 OOF RMSE: {np.sqrt(np.mean((targets - OOF_SVR2) ** 2)):.4f}\")\n",
    "\n",
    "# --- 6B. Train Final Linear Regression Ensemble ---\n",
    "meta_features = np.stack([OOF_BCE, OOF_CE, OOF_SVR1, OOF_SVR2], axis=1)\n",
    "\n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(meta_features, targets)\n",
    "\n",
    "final_oof_preds = np.clip(meta_model.predict(meta_features), 1, 100) \n",
    "final_rmse = np.sqrt(np.mean((targets - final_oof_preds) ** 2))\n",
    "\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(f\"Final 2nd Stage Ensemble OOF RMSE : {final_rmse:.4f}\")\n",
    "print(f\"{'#'*70}\")\n",
    "    \n",
    "# final ensemble OOF predictions and meta-models\n",
    "np.save(os.path.join(OOF_SAVE_DIR, \"oof_final_ensemble.npy\"), final_oof_preds)\n",
    "joblib.dump(meta_model, os.path.join(OOF_SAVE_DIR, \"meta_model.pkl\"))\n",
    "joblib.dump(svr1, os.path.join(OOF_SAVE_DIR, \"svr1_model.pkl\"))\n",
    "joblib.dump(svr2, os.path.join(OOF_SAVE_DIR, \"svr2_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87ce9e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "Final Linear Regression on two SVR Heads and one NN Head ensemble : 19.2612\n",
      "######################################################################\n"
     ]
    }
   ],
   "source": [
    "# --- 6B. Final Linear Regression on two SVR Heads and one NN Head ---\n",
    "meta_features1 = np.stack([OOF_CE, OOF_SVR1, OOF_SVR2], axis=1)\n",
    "\n",
    "meta_model1 = LinearRegression()\n",
    "meta_model1.fit(meta_features1, targets)\n",
    "\n",
    "final_oof_preds1 = np.clip(meta_model1.predict(meta_features1), 1, 100) \n",
    "final_rmse1 = np.sqrt(np.mean((targets - final_oof_preds1) ** 2))\n",
    "\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(f\"Final Linear Regression on two SVR Heads and one NN Head ensemble : {final_rmse1:.4f}\")\n",
    "print(f\"{'#'*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc265d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAPIDS (WSL)",
   "language": "python",
   "name": "rapids-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
