{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9363f76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch 2.6.0+cu124 | CUDA: True\n"
     ]
    }
   ],
   "source": [
    "# Imports, config, utils\n",
    "\n",
    "import os, json, time, random, shutil, gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import timm\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def rmse_score(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=np.float32)\n",
    "    y_pred = np.asarray(y_pred, dtype=np.float32)\n",
    "    return float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
    "\n",
    "def save_json(obj, path):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "print(\"Torch\", torch.__version__, \"| CUDA:\", torch.cuda.is_available())\n",
    "\n",
    "class CFG:\n",
    "    train_csv = \"src/inputs/train.csv\"\n",
    "    train_imgdir = \"src/inputs/train\"\n",
    "    test_csv = \"src/inputs/test.csv\"\n",
    "    test_imgdir = \"src/inputs/test\"\n",
    "    sample_submission = \"src/inputs/sample_submission.csv\"\n",
    "    outdir = \"outputs_mtl_piq_brisque\"\n",
    "    model_name = \"swin_large_patch4_window12_384.ms_in22k\"\n",
    "    img_size = 384\n",
    "    folds = 5\n",
    "    epochs = 10\n",
    "    patience = 5\n",
    "    batch_size = 8\n",
    "    lr = 2e-5\n",
    "    weight_decay = 1e-4\n",
    "    seed = 42\n",
    "    tta = 1\n",
    "    w_paw = 1.0   # Pawpularity loss weight\n",
    "    w_bq  = 0.5   # BRISQUE loss weight\n",
    "\n",
    "set_seed(CFG.seed)\n",
    "os.makedirs(CFG.outdir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9e4b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) PIQ BRISQUE utilities\n",
    "\n",
    "from piq import brisque as piq_brisque\n",
    "from PIL import Image\n",
    "\n",
    "def load_tensor_rgb01(path, img_size=None):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    if img_size is not None:\n",
    "        tfm = T.Compose([\n",
    "            T.Resize(int(img_size*1.15)),\n",
    "            T.CenterCrop(img_size),\n",
    "            T.ToTensor(),           # 0..1 RGB\n",
    "        ])\n",
    "        x = tfm(img)\n",
    "    else:\n",
    "        x = T.ToTensor()(img)\n",
    "    return x\n",
    "\n",
    "def compute_brisque_piq_for_df(df, imgdir, id_col=\"Id\", img_ext=\".jpg\", img_size=384, batch_size=16, device=\"cuda\"):\n",
    "    ids = df[id_col].tolist()\n",
    "    xs = []\n",
    "    for img_id in ids:\n",
    "        p = Path(imgdir) / f\"{img_id}{img_ext}\"\n",
    "        x = load_tensor_rgb01(p, img_size=img_size)    # 0..1 RGB\n",
    "        xs.append(x)\n",
    "    X = torch.stack(xs, 0)\n",
    "    if torch.cuda.is_available() and device == \"cuda\":\n",
    "        X = X.cuda()\n",
    "    scores = []\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        s = piq_brisque(X[i:i+batch_size], data_range=1.0, reduction='none')  # (B,)\n",
    "        scores.append(s.detach().cpu())\n",
    "    scores = torch.cat(scores, 0).float().numpy()\n",
    "    return scores.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efbea97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PIQ BRISQUE for train...\n",
      "Computing PIQ BRISQUE for test...\n",
      "Bin value counts:\n",
      " _bin\n",
      "0    1100\n",
      "1     998\n",
      "2    1158\n",
      "3     940\n",
      "4     842\n",
      "5     948\n",
      "6    1074\n",
      "7     921\n",
      "8     953\n",
      "9     978\n",
      "Name: count, dtype: int64\n",
      "Train/Test shapes: (9912, 16) (8, 14)\n"
     ]
    }
   ],
   "source": [
    "#  Load CSVs, compute PIQ BRISQUE, create robust bins\n",
    "\n",
    "df = pd.read_csv(CFG.train_csv)\n",
    "test_df = pd.read_csv(CFG.test_csv)\n",
    "\n",
    "if \"Pawpularity\" in test_df.columns:\n",
    "    test_df = test_df.drop(columns=[\"Pawpularity\"])\n",
    "\n",
    "print(\"Computing PIQ BRISQUE for train...\")\n",
    "df[\"brisque\"] = compute_brisque_piq_for_df(df, CFG.train_imgdir, img_size=CFG.img_size)\n",
    "print(\"Computing PIQ BRISQUE for test...\")\n",
    "test_df[\"brisque\"] = compute_brisque_piq_for_df(test_df, CFG.test_imgdir, img_size=CFG.img_size)\n",
    "\n",
    "\n",
    "df[\"Pawpularity\"] = pd.to_numeric(df[\"Pawpularity\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"Pawpularity\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "n_unique = df[\"Pawpularity\"].nunique()\n",
    "n_bins = int(min(10, max(3, n_unique)))\n",
    "try:\n",
    "    df[\"_bin\"] = pd.qcut(df[\"Pawpularity\"], q=n_bins, labels=False, duplicates=\"drop\")\n",
    "except Exception:\n",
    "    df[\"_bin\"] = pd.cut(df[\"Pawpularity\"], bins=n_bins, labels=False, include_lowest=True)\n",
    "\n",
    "if df[\"_bin\"].isna().any():\n",
    "    ranks = df[\"Pawpularity\"].rank(method=\"average\")\n",
    "    df[\"_bin\"] = pd.qcut(ranks, q=n_bins, labels=False, duplicates=\"drop\")\n",
    "\n",
    "df[\"_bin\"] = df[\"_bin\"].astype(int)\n",
    "\n",
    "print(\"Bin value counts:\\n\", df[\"_bin\"].value_counts(dropna=False).sort_index())\n",
    "print(\"Train/Test shapes:\", df.shape, test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed67d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "class PawDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, img_size=384, is_train=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.is_train = is_train\n",
    "        if is_train:\n",
    "            self.transform = T.Compose([\n",
    "                T.RandomResizedCrop(img_size, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "                T.RandomHorizontalFlip(p=0.5),\n",
    "                T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = T.Compose([\n",
    "                T.Resize(int(img_size*1.15)),\n",
    "                T.CenterCrop(img_size),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = row[\"Id\"]\n",
    "        img = Image.open(self.img_dir / f\"{img_id}.jpg\").convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "        y = row[\"Pawpularity\"] if \"Pawpularity\" in row.index else np.nan\n",
    "        y_norm = np.float32(y / 100.0) if not np.isnan(y) else np.nan\n",
    "        bq = np.float32(row[\"brisque\"])\n",
    "        return {\"image\": img, \"id\": img_id, \"target_norm\": y_norm, \"brisque\": bq}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8290d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Multi-task model: Swin backbone + Pawpularity & BRISQUE heads\n",
    "\n",
    "class SwinBackboneMulti(nn.Module):\n",
    "    def __init__(self, model_name=\"swin_large_patch4_window12_384.ms_in22k\", emb_dim=128, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=0)\n",
    "        in_features = self.backbone.num_features\n",
    "        self.emb = nn.Linear(in_features, emb_dim)\n",
    "        self.head_paw = nn.Linear(emb_dim, 1)   # Pawpularity \n",
    "        self.head_bq  = nn.Linear(emb_dim, 1)   # BRISQUE \n",
    "\n",
    "    def forward(self, x, return_embedding=False):\n",
    "        feats = self.backbone(x)\n",
    "        emb = F.relu(self.emb(feats), inplace=True)\n",
    "        paw_logit = self.head_paw(emb).squeeze(1)\n",
    "        bq_pred   = self.head_bq(emb).squeeze(1)\n",
    "        out = {\"paw_logit\": paw_logit, \"brisque_pred\": bq_pred}\n",
    "        if return_embedding:\n",
    "            return out, emb\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Train/validate and extract embeddings\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, scaler, device, w_paw=1.0, w_bq=0.5):\n",
    "    model.train()\n",
    "    bce = nn.BCEWithLogitsLoss()\n",
    "    l1  = nn.SmoothL1Loss(beta=1.0)\n",
    "    losses = []\n",
    "    for batch in loader:\n",
    "        x = batch[\"image\"].to(device, non_blocking=True)\n",
    "        y_paw = batch[\"target_norm\"].to(device)  # 0..1\n",
    "        y_bq  = batch[\"brisque\"].to(device)      # ~0..100\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(device_type=\"cuda\", enabled=True):\n",
    "            out = model(x)\n",
    "            loss_paw = bce(out[\"paw_logit\"], y_paw)\n",
    "            loss_bq  = l1(out[\"brisque_pred\"], y_bq)\n",
    "            loss = w_paw*loss_paw + w_bq*loss_bq\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer); scaler.update()\n",
    "        losses.append(loss.item())\n",
    "        del x, y_paw, y_bq\n",
    "        torch.cuda.empty_cache()\n",
    "    return float(np.mean(losses))\n",
    "\n",
    "def validate_epoch(model, loader, device):\n",
    "    model.eval()\n",
    "    preds, gts = [], []\n",
    "    for batch in loader:\n",
    "        x = batch[\"image\"].to(device, non_blocking=True)\n",
    "        y = batch[\"target_norm\"].numpy()\n",
    "        out = model(x)\n",
    "        prob = torch.sigmoid(out[\"paw_logit\"]).detach().cpu().numpy() * 100.0\n",
    "        preds.append(prob); gts.append(y * 100.0)\n",
    "        del x\n",
    "        torch.cuda.empty_cache()\n",
    "    preds = np.concatenate(preds); gts = np.concatenate(gts)\n",
    "    return rmse_score(gts, preds)\n",
    "\n",
    "def extract_embeddings(model, loader, device):\n",
    "    model.eval()\n",
    "    ids, embs, preds_paw, preds_bq = [], [], [], []\n",
    "    for batch in loader:\n",
    "        x = batch[\"image\"].to(device, non_blocking=True)\n",
    "        out, emb = model(x, return_embedding=True)\n",
    "        paw = torch.sigmoid(out[\"paw_logit\"]).detach().cpu().numpy() * 100.0\n",
    "        bq  = out[\"brisque_pred\"].detach().cpu().numpy()\n",
    "        embs.append(emb.detach().cpu().numpy())\n",
    "        preds_paw.append(paw)\n",
    "        preds_bq.append(bq)\n",
    "        ids.extend(batch[\"id\"])\n",
    "        del x\n",
    "        torch.cuda.empty_cache()\n",
    "    return ids, np.concatenate(embs), np.concatenate(preds_paw), np.concatenate(preds_bq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212e88fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Fold 0 ==========\n",
      "Fold 0 | Epoch 1 | Train loss 3.9356 | Val RMSE 20.1494 | 1499.1s\n",
      "Fold 0 | Epoch 2 | Train loss 2.8710 | Val RMSE 19.5414 | 4331.5s\n",
      "Fold 0 | Epoch 3 | Train loss 2.5800 | Val RMSE 19.2912 | 3956.6s\n",
      "Fold 0 | Epoch 4 | Train loss 2.3841 | Val RMSE 19.3116 | 3969.8s\n",
      "Fold 0 | Epoch 5 | Train loss 2.1783 | Val RMSE 18.5916 | 5053.9s\n",
      "Fold 0 | Epoch 6 | Train loss 2.0478 | Val RMSE 18.7837 | 4670.8s\n",
      "Fold 0 | Epoch 7 | Train loss 1.8707 | Val RMSE 18.7320 | 4542.5s\n",
      "Fold 0 | Epoch 8 | Train loss 1.7737 | Val RMSE 18.9551 | 4896.4s\n",
      "Fold 0 | Epoch 9 | Train loss 1.6296 | Val RMSE 18.6201 | 4312.3s\n",
      "Fold 0 | Epoch 10 | Train loss 1.5435 | Val RMSE 18.8069 | 4716.4s\n",
      "Early stopping at epoch 10, best RMSE 18.5916\n",
      "\n",
      "========== Fold 1 ==========\n",
      "Fold 1 | Epoch 1 | Train loss 3.9496 | Val RMSE 20.7110 | 5614.0s\n",
      "Fold 1 | Epoch 2 | Train loss 2.8897 | Val RMSE 20.2042 | 5678.6s\n",
      "Fold 1 | Epoch 3 | Train loss 2.5904 | Val RMSE 19.6665 | 5671.3s\n",
      "Fold 1 | Epoch 4 | Train loss 2.3869 | Val RMSE 19.4245 | 5409.0s\n",
      "Fold 1 | Epoch 5 | Train loss 2.2042 | Val RMSE 19.2035 | 4726.3s\n"
     ]
    }
   ],
   "source": [
    "#  Cross-validation loop\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "skf = StratifiedKFold(n_splits=CFG.folds, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "oof_rows = []\n",
    "test_preds_folds = []\n",
    "fold_summaries = {}\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(df, df[\"_bin\"])):\n",
    "    print(f\"\\n========== Fold {fold} ==========\")\n",
    "    fold_dir = Path(CFG.outdir) / f\"fold{fold}\"\n",
    "    if fold_dir.exists():\n",
    "        shutil.rmtree(fold_dir)\n",
    "    fold_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    tr_df = df.iloc[tr_idx].copy().reset_index(drop=True)\n",
    "    va_df = df.iloc[va_idx].copy().reset_index(drop=True)\n",
    "\n",
    "    train_ds = PawDataset(tr_df, CFG.train_imgdir, img_size=CFG.img_size, is_train=True)\n",
    "    valid_ds = PawDataset(va_df, CFG.train_imgdir, img_size=CFG.img_size, is_train=False)\n",
    "    test_ds  = PawDataset(test_df.assign(Pawpularity=np.nan), CFG.test_imgdir, img_size=CFG.img_size, is_train=False)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=CFG.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    valid_loader = DataLoader(valid_ds, batch_size=CFG.batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=CFG.batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    model = SwinBackboneMulti(model_name=CFG.model_name, emb_dim=128, pretrained=True).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    scaler = torch.amp.GradScaler(device=\"cuda\", enabled=True)\n",
    "\n",
    "    best_rmse = float(\"inf\")\n",
    "    best_path = fold_dir / \"best.pt\"\n",
    "    patience_count = 0\n",
    "\n",
    "    for epoch in range(1, CFG.epochs + 1):\n",
    "        t0 = time.time()\n",
    "        tr_loss = train_one_epoch(model, train_loader, optimizer, scaler, device, CFG.w_paw, CFG.w_bq)\n",
    "        va_rmse = validate_epoch(model, valid_loader, device)\n",
    "        print(f\"Fold {fold} | Epoch {epoch} | Train loss {tr_loss:.4f} | Val RMSE {va_rmse:.4f} | {time.time()-t0:.1f}s\")\n",
    "        if va_rmse < best_rmse - 1e-4:\n",
    "            best_rmse = va_rmse\n",
    "            patience_count = 0\n",
    "            torch.save({\"state_dict\": model.state_dict(), \"rmse\": best_rmse}, best_path)\n",
    "        else:\n",
    "            patience_count += 1\n",
    "            if patience_count >= CFG.patience:\n",
    "                print(f\"Early stopping at epoch {epoch}, best RMSE {best_rmse:.4f}\")\n",
    "                break\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    ckpt = torch.load(best_path, map_location=\"cpu\")\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    del optimizer, scaler, ckpt\n",
    "    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    va_ids, va_embs, va_paw, va_bq = extract_embeddings(model, valid_loader, device)\n",
    "    te_ids, te_embs, te_paw, te_bq = extract_embeddings(model, test_loader, device)\n",
    "    tr_ids, tr_embs, tr_paw, tr_bq = extract_embeddings(model, train_loader, device)\n",
    "\n",
    "    svr = Pipeline([(\"scaler\", StandardScaler()), (\"svr\", SVR(C=10.0, epsilon=0.2, kernel=\"rbf\"))])\n",
    "    y_tr = tr_df[\"Pawpularity\"].values.astype(np.float32)\n",
    "    svr.fit(tr_embs, y_tr)\n",
    "\n",
    "    va_svr = svr.predict(va_embs).astype(np.float32)\n",
    "    te_svr = svr.predict(te_embs).astype(np.float32)\n",
    "\n",
    "    va_ens = (va_paw + va_svr) / 2.0\n",
    "    te_ens = (te_paw + te_svr) / 2.0\n",
    "\n",
    "    for i, vid in enumerate(va_ids):\n",
    "        oof_rows.append({\n",
    "            \"Id\": vid,\n",
    "            \"fold\": fold,\n",
    "            \"y_true\": float(va_df.loc[va_df[\"Id\"] == vid, \"Pawpularity\"].values[0]),\n",
    "            \"pred_mlp\": float(va_paw[i]),\n",
    "            \"pred_svr\": float(va_svr[i]),\n",
    "            \"pred_ens\": float(va_ens[i]),\n",
    "            \"pred_brisque\": float(va_bq[i]),\n",
    "        })\n",
    "\n",
    "    np.save(fold_dir / \"val_embeddings.npy\", va_embs)\n",
    "    np.save(fold_dir / \"train_embeddings.npy\", tr_embs)\n",
    "    np.save(fold_dir / \"test_embeddings.npy\", te_embs)\n",
    "    np.save(fold_dir / \"val_pred_mlp.npy\", va_paw)\n",
    "    np.save(fold_dir / \"val_pred_svr.npy\", va_svr)\n",
    "    np.save(fold_dir / \"val_pred_ens.npy\", va_ens)\n",
    "    np.save(fold_dir / \"test_pred_mlp.npy\", te_paw)\n",
    "    np.save(fold_dir / \"test_pred_svr.npy\", te_svr)\n",
    "    np.save(fold_dir / \"test_pred_ens.npy\", te_ens)\n",
    "    np.save(fold_dir / \"val_pred_brisque.npy\", va_bq)\n",
    "    np.save(fold_dir / \"test_pred_brisque.npy\", te_bq)\n",
    "    torch.save(svr, fold_dir / \"svr.pkl\")\n",
    "\n",
    "    fold_summaries[f\"fold_{fold}\"] = {\"best_val_rmse\": best_rmse, \"val_count\": len(va_ids), \"test_count\": len(te_ids)}\n",
    "    test_preds_folds.append(pd.DataFrame({\"Id\": te_ids, f\"fold{fold}\": te_ens}))\n",
    "\n",
    "    del train_loader, valid_loader, test_loader\n",
    "    del train_ds, valid_ds, test_ds\n",
    "    del tr_embs, va_embs, te_embs, tr_paw, va_paw, te_paw, va_svr, te_svr, va_ens, te_ens\n",
    "    del model, svr\n",
    "    gc.collect(); torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00d533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Save OOF and submission\n",
    "\n",
    "oof_df = pd.DataFrame(oof_rows)\n",
    "oof_df.to_csv(Path(CFG.outdir) / \"oof_predictions.csv\", index=False)\n",
    "oof_rmse = rmse_score(oof_df[\"y_true\"].values, oof_df[\"pred_ens\"].values)\n",
    "print(f\"OOF RMSE (ensemble): {oof_rmse:.4f}\")\n",
    "fold_summaries = {\"oof_rmse\": oof_rmse, **fold_summaries}\n",
    "save_json(fold_summaries, Path(CFG.outdir) / \"fold_summaries.json\")\n",
    "\n",
    "sub_base = pd.read_csv(CFG.sample_submission)\n",
    "sub = sub_base[[\"Id\"]].copy()\n",
    "for df_fold in test_preds_folds:\n",
    "    sub = sub.merge(df_fold, on=\"Id\", how=\"left\")\n",
    "fold_cols = [c for c in sub.columns if c.startswith(\"fold\")]\n",
    "sub[\"Pawpularity\"] = sub[fold_cols].mean(axis=1).clip(1, 100)\n",
    "sub[[\"Id\", \"Pawpularity\"]].to_csv(Path(CFG.outdir) / \"submission.csv\", index=False)\n",
    "print(\"Saved:\", Path(CFG.outdir) / \"submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd4a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Ensembling\n",
    "\n",
    "oof_path = Path(CFG.outdir) / \"oof_predictions.csv\"\n",
    "oof = pd.read_csv(oof_path)\n",
    "\n",
    "y_true   = oof[\"y_true\"].values.astype(np.float32)\n",
    "pred_mlp = oof[\"pred_mlp\"].values.astype(np.float32)\n",
    "pred_svr = oof[\"pred_svr\"].values.astype(np.float32)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "\n",
    "rmse_mlp = rmse(y_true, pred_mlp)\n",
    "rmse_svr = rmse(y_true, pred_svr)\n",
    "rmse_avg = rmse(y_true, 0.5 * pred_mlp + 0.5 * pred_svr)\n",
    "\n",
    "def find_best_weight(y_true, mlp, svr):\n",
    "    best_w = 0.0\n",
    "    best_rmse = 999.0\n",
    "    for w in np.linspace(0, 1, 1001):\n",
    "        blended = w * mlp + (1 - w) * svr\n",
    "        r = rmse(y_true, blended)\n",
    "        if r < best_rmse:\n",
    "            best_rmse = r\n",
    "            best_w = w\n",
    "    return best_w, best_rmse\n",
    "\n",
    "best_w, best_rmse = find_best_weight(y_true, pred_mlp, pred_svr)\n",
    "\n",
    "print(\"=======================================\")\n",
    "print(\"           OOF RMSE RESULTS\")\n",
    "print(\"=======================================\")\n",
    "print(f\" MLP only RMSE              : {rmse_mlp:.6f}\")\n",
    "print(f\" SVR only RMSE              : {rmse_svr:.6f}\")\n",
    "print(f\" Simple Average (0.5/0.5)   : {rmse_avg:.6f}\")\n",
    "print(\"---------------------------------------\")\n",
    "print(f\" Optimal Blend Weight (MLP) : {best_w:.4f}\")\n",
    "print(f\" Optimal Blend RMSE         : {best_rmse:.6f}\")\n",
    "print(\"=======================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe7dcfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
